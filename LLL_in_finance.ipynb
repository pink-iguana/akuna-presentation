{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01546ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from fpylll import IntegerMatrix, LLL\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stock data using yfinance\n",
    "\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)\n",
    "    data = data.dropna(axis=1, how='all')  # Drop columns with all NaN values\n",
    "    data = data.dropna(axis=0, how='all')  # Drop rows with all NaN values\n",
    "    data = data.ffill()  # Fill NaN values with the previous valid observation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b361537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['^GSPC','AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-01-01'\n",
    "data = fetch_stock_data(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1d05025",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = data['Close'].pct_change().dropna()  # Calculate daily returns\n",
    "sp500_returns = returns['^GSPC']  # S&P 500 returns\n",
    "betas = returns.corrwith(sp500_returns) # Beta of each stock\n",
    "volatilities = returns.std()  # Volatility of each stock\n",
    "volume_usd = data['Volume'] * data['Close']  # Convert volume to USD\n",
    "amihud_illiquidity = (np.abs(returns)/volume_usd).dropna().mean(axis=0)  # Amihud Illiquidity Measure\n",
    "left_threshold = returns['^GSPC'].quantile(0.05)\n",
    "right_threshold = returns['^GSPC'].quantile(0.95)\n",
    "tail_data = returns[(returns['^GSPC'] >= right_threshold) | (returns['^GSPC'] <= left_threshold)]\n",
    "tail_corr = tail_data.corr()\n",
    "tail_risk = tail_corr['^GSPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9abf3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_risk_matrix(raw_risk_matrix):\n",
    "    # standardize the risk matrix using min-max scaling\n",
    "    risk_matrix = (raw_risk_matrix - raw_risk_matrix.min()) / (raw_risk_matrix.max() - raw_risk_matrix.min())\n",
    "    return risk_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25844a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate risk vectors (beta, sector risk, volatility)\n",
    "\n",
    "def calculate_risk_matrix(data):\n",
    "    returns = data['Close'].pct_change().dropna()  # Calculate daily returns\n",
    "    sp500_returns = returns['^GSPC']  # S&P 500 returns\n",
    "    betas = returns.corrwith(sp500_returns) # Beta of each stock\n",
    "    volatilities = returns.std()  # Volatility of each stock\n",
    "    volume_usd = data['Volume'] * data['Close']  # Convert volume to USD\n",
    "    amihud_illiquidity = (np.abs(returns)/volume_usd).dropna().mean(axis=0)  # Amihud Illiquidity Measure\n",
    "    left_threshold = returns['^GSPC'].quantile(0.05)\n",
    "    right_threshold = returns['^GSPC'].quantile(0.95)\n",
    "    tail_data = returns[(returns['^GSPC'] >= right_threshold) | (returns['^GSPC'] <= left_threshold)]\n",
    "    tail_corr = tail_data.corr()\n",
    "    tail_risk = tail_corr['^GSPC']\n",
    "    raw_risk_matrix = pd.DataFrame({\n",
    "        'Beta': betas,\n",
    "        'Volatility': volatilities,\n",
    "        'Amihud Illiquidity': amihud_illiquidity,\n",
    "        'Tail Risk': tail_risk\n",
    "    })\n",
    "    # standardize the risk matrix using min-max scaling\n",
    "    risk_matrix = standardise_risk_matrix(raw_risk_matrix)\n",
    "    #drop GSPC row\n",
    "    risk_matrix = risk_matrix.drop(index='^GSPC', errors='ignore')\n",
    "\n",
    "    return risk_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed730c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_matrix = calculate_risk_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb92cee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Amihud Illiquidity</th>\n",
       "      <th>Tail Risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.640386</td>\n",
       "      <td>0.245469</td>\n",
       "      <td>0.277572</td>\n",
       "      <td>0.802699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.288709</td>\n",
       "      <td>0.291506</td>\n",
       "      <td>0.367738</td>\n",
       "      <td>0.178427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.615798</td>\n",
       "      <td>0.193891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.711088</td>\n",
       "      <td>0.198894</td>\n",
       "      <td>0.459873</td>\n",
       "      <td>0.842417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.387232</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Beta  Volatility  Amihud Illiquidity  Tail Risk\n",
       "Ticker                                                     \n",
       "AAPL    0.640386    0.245469            0.277572   0.802699\n",
       "AMZN    0.288709    0.291506            0.367738   0.178427\n",
       "GOOGL   0.615798    0.193891            1.000000   0.777819\n",
       "MSFT    0.711088    0.198894            0.459873   0.842417\n",
       "TSLA    0.000000    1.000000            0.387232   0.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_short_vector_coeffs(risk_matrix):\n",
    "    # assume that the risk vectors are basis vectors of a lattice and apply LLL reduction\n",
    "    # we want each risk vector to be a column in the risk matrix\n",
    "    R = IntegerMatrix.from_matrix(risk_matrix.values.T)\n",
    "    LLL.reduction(R)\n",
    "    # Extract the reduced basis vectors\n",
    "    reduced_vectors = np.array(R).T\n",
    "    # Find the coefficients of the short vector in the original basis\n",
    "    coeffs = np.linalg.lstsq(risk_matrix.values, reduced_vectors, rcond=None)[0]\n",
    "    # Round the coefficients to the nearest integer\n",
    "    coeffs = np.round(coeffs).astype(int)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ce532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape S&P 500 tickers from Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "table = pd.read_html(url)\n",
    "sp500 = table[0]\n",
    "tickers = sp500['Symbol'].tolist()\n",
    "\n",
    "# convert tickers to yfinance format\n",
    "tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "tickers = ['^GSPC'] + tickers  # Add S&P 500 index ticker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
